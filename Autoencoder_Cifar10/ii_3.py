# -*- coding: utf-8 -*-
"""II_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ha-xF6SnK2qqVp6GQzhORllP6Gt5Xmie
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import cifar10
import matplotlib.pyplot as plt

from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import to_categorical

latent_dim = 1024  # Размерность латентного пространства
batch_size = 16
epochs = 12

(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

encoder_inputs = keras.Input(shape=(32, 32, 3))
x = layers.Conv2D(64, 3, strides=2, padding="same")(encoder_inputs)
x = layers.BatchNormalization()(x)
x = layers.LeakyReLU(negative_slope=0.2)(x)
x = layers.Conv2D(128, 3, strides=2, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.LeakyReLU(negative_slope=0.2)(x)
x = layers.Conv2D(256, 3, strides=2, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.LeakyReLU(negative_slope=0.2)(x)
x = layers.Flatten()(x)
x = layers.Dense(512, activation="relu")(x)

z_mean = layers.Dense(latent_dim, name="z_mean")(x)
z_log_var = layers.Dense(latent_dim, name="z_log_var")(x)

class Sampling(layers.Layer):
    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = keras.backend.shape(z_mean)[0]
        dim = keras.backend.shape(z_mean)[1]
        epsilon = keras.backend.random_normal(shape=(batch, dim))
        return z_mean + keras.backend.exp(0.5 * z_log_var) * epsilon

z = Sampling()([z_mean, z_log_var])

encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")

latent_inputs = keras.Input(shape=(latent_dim,))
x = layers.Dense(8*8*128, activation="relu")(latent_inputs)
x = layers.Reshape((8, 8, 128))(x)
x = layers.Conv2DTranspose(256, 3, strides=2, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.LeakyReLU(negative_slope=0.2)(x)
x = layers.Conv2DTranspose(128, 3, strides=2, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.LeakyReLU(negative_slope=0.2)(x)
x = layers.Conv2DTranspose(64, 3, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.LeakyReLU(negative_slope=0.2)(x)
decoder_outputs = layers.Conv2D(3, 3, activation="sigmoid", padding="same")(x)

decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")

class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super().__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name="total_loss")
        self.reconstruction_loss_tracker = keras.metrics.Mean(name="reconstruction_loss")
        self.kl_loss_tracker = keras.metrics.Mean(name="kl_loss")

    @property
    def metrics(self):
        return [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.kl_loss_tracker,
        ]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encoder(data)
            reconstruction = self.decoder(z)
            reconstruction_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.mse(data, reconstruction),
                    axis=(1, 2)
                )
            )
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            beta = 0.1
            total_loss = reconstruction_loss + beta * kl_loss

        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {m.name: m.result() for m in self.metrics}

vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(x_train, epochs=epochs, batch_size=batch_size)

plt.plot(vae.history.history['reconstruction_loss'], label='Recon Loss')
plt.plot(vae.history.history['kl_loss'], label='KL Loss')
plt.title('Loss Dynamics')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.savefig('autoencoder_train.png')
plt.close()

test_reconstructions = vae.decoder.predict(encoder.predict(x_test[:10])[2], verbose=0)
plt.figure(figsize=(20, 4))
for i in range(10):
    ax = plt.subplot(2, 10, i + 1)
    plt.imshow(x_test[i])
    plt.axis("off")

    ax = plt.subplot(2, 10, i + 11)
    plt.imshow(test_reconstructions[i])
    plt.axis("off")
plt.savefig('reconstractions.png')
plt.close()

_, _, latent_vectors = encoder.predict(x_test, batch_size=128, verbose=1)

# Визуализация распределения случайных 6 компонент латентного пространства (оно нормальное, а значит всё хорошо)
plt.figure(figsize=(15, 6))
for i in range(6):
    plt.subplot(2, 3, i+1)
    plt.hist(latent_vectors[:, np.random.randint(0, latent_dim)], bins=50, density=True)
    plt.title(f"Latent dim {i+1}")
    plt.grid(True)
plt.tight_layout()
plt.savefig('6_random_axes_normalization_proof.png')
plt.close()

from sklearn.decomposition import PCA

# Проекция на 2 главные компоненты
pca = PCA(n_components=2)
latent_2d = pca.fit_transform(latent_vectors)

# Визуализация
plt.figure(figsize=(12, 10))
plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=y_test.flatten(),
            cmap='tab10', alpha=0.6, edgecolors='w')
plt.colorbar(ticks=range(10), label='Classes')
plt.title("PCA of Latent Space")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.grid(True)
plt.show()
plt.savefig('2_major_pca_components_normalization_proof.png')
plt.close()

# Визуализация проекций картинок на две главные компоненты в латентном пространстве автоэнкодера показывает, что все изображения находятся в ограниченной области и распределны нормально

class_means = []
for class_idx in range(10):
    class_images = x_train[y_train.flatten() == class_idx]
    _, _, latent_vectors = encoder.predict(class_images, verbose=0)
    class_means.append(np.mean(latent_vectors, axis=0))

noise_scale = 0.75
generated_images = []
generated_labels = []

for class_idx in range(10):
    # Генерируем все векторы для класса одним вызовом
    mean_vector = class_means[class_idx]
    noise = np.random.normal(scale=noise_scale, 
                            size=(5000, latent_dim))
    latent_vectors = mean_vector + noise
    
    # Декодируем батчами по 256
    class_images = []
    for batch in np.array_split(latent_vectors, 5000//256 + 1):
        images = decoder.predict(batch, verbose=0)
        class_images.append(images)
    
    generated_images.append(np.concatenate(class_images))
    generated_labels.extend([class_idx]*5000)

generated_images = np.concatenate(generated_images)
generated_labels = np.array(generated_labels)

print(generated_images.shape)  # Должно быть (50000, 32, 32, 3)
print(generated_labels.shape)  # Должно быть (50000,)

import random

plt.figure(figsize=(10,5))
for i in range(10):
    plt.subplot(2,5,i+1)
    idx = random.randint(1, 50000)
    plt.imshow(generated_images[idx])
    plt.title(f"Class {generated_labels[idx]}")
plt.savefig('random_generated_mean_reconstractions_with_noise.png')
plt.close()

generated_labels_onehot = to_categorical(generated_labels, num_classes=10)
y_test_onehot = to_categorical(y_test, num_classes=10)

model = keras.Sequential([
    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3), padding='same'),
    layers.BatchNormalization(),
    layers.SpatialDropout2D(rate=0.2),
    layers.MaxPooling2D(pool_size=(2, 2)),

    layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.SpatialDropout2D(rate=0.2),
    layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.SpatialDropout2D(rate=0.2),
    layers.MaxPooling2D(pool_size=(2, 2)),

    layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.SpatialDropout2D(rate=0.2),
    layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.SpatialDropout2D(rate=0.2),
    layers.MaxPooling2D(pool_size=(2, 2)),

    layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.SpatialDropout2D(rate=0.2),
    layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.SpatialDropout2D(rate=0.2),
    layers.Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.SpatialDropout2D(rate=0.2),
    layers.MaxPooling2D(pool_size=(2, 2)),

    layers.Flatten(),
    layers.Dense(units=1024, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(units=10, activation='softmax')
])

#print(model.summary())

# Компиляция нейросети (выбор оптимизатора, функции ошибки и характеристики точности нейросети)
#my_optimizer = keras.optimizers.SGD(learning_rate = 0.01, nesterov = True)
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Остановка обучения, если точность в выборке валидации долго не изменяется
early_stopping = EarlyStopping(
    monitor='val_accuracy',
    mode='auto',
    patience=5,
    verbose=1
)

history = model.fit(generated_images, generated_labels_onehot,
                    epochs=40,
                    batch_size=60,
                    validation_data=(x_test, y_test_onehot), callbacks=[early_stopping])

# Визуализация результатов
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.savefig('old_nn_train.png')
plt.close()